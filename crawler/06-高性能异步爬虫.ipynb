{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "高性能异步爬虫\n",
    "目的：在爬虫中使用异步实现高性能的数据爬取操作。\n",
    "\n",
    "异步爬虫的方式：\n",
    "    - 1.多线程，多进程（不建议）：\n",
    "        好处：可以为相关阻塞的操作单独开启线程或者进程，阻塞操作就可以异步执行。\n",
    "        弊端：无法无限制的开启多线程或者多进程。\n",
    "    - 2.线程池、进程池（适当的使用）：\n",
    "        好处：我们可以降低系统对进程或者线程创建和销毁的一个频率，从而很好的降低系统的开销。\n",
    "        弊端：池中线程或进程的数量是有上限。\n",
    "\n",
    "- 3.单线程+异步协程（推荐）：\n",
    "    event_loop：事件循环，相当于一个无限循环，我们可以把一些函数注册到这个事件循环上，\n",
    "    当满足某些条件的时候，函数就会被循环执行。\n",
    "\n",
    "    coroutine：协程对象，我们可以将协程对象注册到事件循环中，它会被事件循环调用。\n",
    "    我们可以使用 async 关键字来定义一个方法，这个方法在调用时不会立即被执行，而是返回\n",
    "    一个协程对象。\n",
    "\n",
    "    task：任务，它是对协程对象的进一步封装，包含了任务的各个状态。\n",
    "\n",
    "    future：代表将来执行或还没有执行的任务，实际上和 task 没有本质区别。\n",
    "\n",
    "    async 定义一个协程.\n",
    "\n",
    "    await 用来挂起阻塞方法的执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在爬取  https://sc.chinaz.com/psd/index.html?business=0\n",
      "手绘风格感恩节传单海报设计 下载成功!\n",
      "美容护肤行业商务名片模板 下载成功!\n",
      "夏日咖啡饮品特价招贴海报设计 下载成功!\n",
      "手工展三折页宣传PSD模板 下载成功!\n",
      "暖房派对海报PSD设计源文件 下载成功!\n",
      "开学季返校横幅ps素材 下载成功!\n",
      "唇釉化妆品广告传单设计 下载成功!\n",
      "手工艺术展宣传单模板设计 下载成功!\n",
      "宠物店宠物护理折扣传单A5模板 下载成功!\n",
      "周岁宝宝生日宴会邀请模板A5 下载成功!\n",
      "扁平插画风格房地产海报设计 下载成功!\n",
      "可爱卡通风格周岁生日海报设计 下载成功!\n",
      "曲棍球运动传单PS素材 下载成功!\n",
      "全民营养周宣传海报PSD模板 下载成功!\n",
      "游戏活动传单设计源文件 下载成功!\n",
      "世界心脏日公益活动邀请模板 下载成功!\n",
      "卡通插画风格市场营销传单设计 下载成功!\n",
      "游戏电竞海报PSD设计源文件 下载成功!\n",
      "房地产建筑卡通插画风格传单设计 下载成功!\n",
      "蓝色清新花卉派对邀请A5模板 下载成功!\n",
      "单线程爬取时间: 70.31480479240417 s\n"
     ]
    }
   ],
   "source": [
    "# 单线程\n",
    "import os\n",
    "import requests\n",
    "from lxml import etree\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "import threading\n",
    "\n",
    "# 下载 https://sc.chinaz.com/psd/?business=0 免费设计模版\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "if not os.path.exists(\"d_template\"):\n",
    "    os.mkdir(\"d_template\")\n",
    "\n",
    "def download_template(src, name):\n",
    "    try:\n",
    "        template = requests.get(url=src, headers=headers).content.decode('utf-8')\n",
    "        template_tree = etree.HTML(template)\n",
    "        download_url = template_tree.xpath('//div[@class=\"c-div clearfix\"]/a/@href')[0]\n",
    "        template = requests.get(url=download_url, headers=headers).content\n",
    "        with open(\"d_template/\"+name+\".zip\", \"wb\") as fp:\n",
    "            fp.write(template)\n",
    "        print(f\"{name} 下载成功!\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name} 下载失败: {e}\")\n",
    "\n",
    "urls = []\n",
    "\n",
    "# 分页\n",
    "def scrape_page(index):\n",
    "    page = \"index\"+(\"_\"+str(index) if index > 1 else \"\")+\".html\"\n",
    "    url = 'https://sc.chinaz.com/psd/'+page+\"?business=0\"\n",
    "    print(f\"正在爬取 \", url)\n",
    "    page_text = requests.get(url=url, headers=headers).content.decode('utf-8')\n",
    "    tree = etree.HTML(page_text)\n",
    "    items = tree.xpath('//div[@class=\"bot-div\"]/a')\n",
    "    for item in items:\n",
    "        name = item.xpath('./text()')[0]\n",
    "        src = \"https:\"+item.xpath('./@href')[0]\n",
    "        # download_template(src, name)\n",
    "        urls.append((src, name))\n",
    "\n",
    "scrape_page(1)\n",
    "start_time = time.time()\n",
    "for src, name in urls:\n",
    "    download_template(src, name)\n",
    "end_time = time.time()\n",
    "print(f\"单线程爬取时间: {end_time-start_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在爬取  https://sc.chinaz.com/psd/index.html?business=0\n",
      "668 手工艺术展宣传单模板设计 下载成功!\n",
      "34976 暖房派对海报PSD设计源文件 下载成功!\n",
      "18920 美容护肤行业商务名片模板 下载成功!\n",
      "668 宠物店宠物护理折扣传单A5模板 下载成功!\n",
      "34976 周岁宝宝生日宴会邀请模板A5 下载成功!\n",
      "34976 曲棍球运动传单PS素材 下载成功!\n",
      "668 可爱卡通风格周岁生日海报设计 下载成功!\n",
      "668 世界心脏日公益活动邀请模板 下载成功!\n",
      "668 游戏活动传单设计源文件 下载成功!\n",
      "668 卡通插画风格市场营销传单设计 下载成功!\n",
      "668 游戏电竞海报PSD设计源文件 下载成功!\n",
      "18920 扁平插画风格房地产海报设计 下载成功!\n",
      "668 房地产建筑卡通插画风格传单设计 下载成功!\n",
      "18920 蓝色清新花卉派对邀请A5模板 下载成功!\n",
      "32296 开学季返校横幅ps素材 下载成功!\n",
      "34976 全民营养周宣传海报PSD模板 下载成功!\n",
      "35340 手工展三折页宣传PSD模板 下载成功!\n",
      "33320 唇釉化妆品广告传单设计 下载成功!\n",
      "32364 手绘风格感恩节传单海报设计 下载成功!\n",
      "33660 夏日咖啡饮品特价招贴海报设计 下载成功!\n",
      "单线程爬取时间: 43.727301597595215 s\n"
     ]
    }
   ],
   "source": [
    "# 线程池\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from lxml import etree\n",
    "from multiprocessing.dummy import Pool\n",
    "import time\n",
    "import threading\n",
    "\n",
    "# 下载 https://sc.chinaz.com/psd/?business=0 免费设计模版\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "if not os.path.exists(\"d_template\"):\n",
    "    os.mkdir(\"d_template\")\n",
    "\n",
    "def download_template(dict):\n",
    "    # thread_name = threading.current_thread().name\n",
    "    thread_name = threading.get_native_id()\n",
    "    try:\n",
    "        src, name = dict['src'], dict['name']\n",
    "        template = requests.get(\n",
    "            url=src, headers=headers).content.decode('utf-8')\n",
    "        template_tree = etree.HTML(template)\n",
    "        download_url = template_tree.xpath(\n",
    "            '//div[@class=\"c-div clearfix\"]/a/@href')[0]\n",
    "        template = requests.get(url=download_url, headers=headers).content\n",
    "        with open(\"d_template/\"+name+\".zip\", \"wb\") as fp:\n",
    "            fp.write(template)\n",
    "        print(f\"{thread_name} {name} 下载成功!\")\n",
    "    except Exception as e:\n",
    "        print(f\"{thread_name} {name} 下载失败: {e}\")\n",
    "\n",
    "urls = []\n",
    "\n",
    "# 分页\n",
    "def scrape_page(index):\n",
    "    page = \"index\"+(\"_\"+str(index) if index > 1 else \"\")+\".html\"\n",
    "    url = 'https://sc.chinaz.com/psd/'+page+\"?business=0\"\n",
    "    print(f\"正在爬取 \", url)\n",
    "    page_text = requests.get(url=url, headers=headers).content.decode('utf-8')\n",
    "    tree = etree.HTML(page_text)\n",
    "    items = tree.xpath('//div[@class=\"bot-div\"]/a')\n",
    "    for item in items:\n",
    "        name = item.xpath('./text()')[0]\n",
    "        src = \"https:\"+item.xpath('./@href')[0]\n",
    "        # download_template(src, name)\n",
    "        urls.append({'src': src, 'name': name})\n",
    "\n",
    "scrape_page(1)\n",
    "start_time = time.time()\n",
    "pool = Pool(4)\n",
    "pool.map(download_template, urls)\n",
    "pool.close()\n",
    "pool.join()\n",
    "end_time = time.time()\n",
    "print(f\"单线程爬取时间: {end_time-start_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9772 少年般绚丽.mp4 下载成功!\n",
      "9772 奶奶的新时代.mp4 下载成功!\n",
      "9772 微短剧《赵小姐的日记》｜一本日记，两段情缘。.mp4 下载成功!\n",
      "9772 以史为镜，情缘相连。文物修复师恋人探寻前世，以期今生.mp4 下载成功!\n",
      "9772 网剧_1818_编辑部___网络世界迷人眼.mp4 下载成功!\n",
      "9772 如今可选择的选项越来越多，有选择困难症怎么破？.mp4 下载成功!\n",
      "9772 网台同播纪录片《赶集故事会》走进百姓生活_感受众生百态.mp4 下载成功!\n",
      "9772 以为夏天的哈尔滨不会有雪，梦幻冰雪馆让你过足冰雪瘾！.mp4 下载成功!\n",
      "9772 #两极穿越龙江行｜东极黑瞎子岛的岛主竟然是萌呆的黑熊们.mp4 下载成功!\n",
      "9772 #两极穿越龙江行｜世界慢慢游,去18度的漠河避暑两日游攻略.mp4 下载成功!\n",
      "下载视频耗时: 2.521181583404541 s\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import requests\n",
    "from lxml import etree\n",
    "import re, json, os, time, threading\n",
    "from multiprocessing.dummy import Pool\n",
    "\n",
    "# 使用线程池爬取梨视频的视频数据\n",
    "\n",
    "if not os.path.exists('./videos'):\n",
    "    os.mkdir('./videos')\n",
    "    \n",
    "start_time = time.time()\n",
    "\n",
    "session = requests.session()\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'\n",
    "}\n",
    "# 添加到session中是全局的 后面每个get/post请求都会携带这个headers\n",
    "session.headers.update(headers)\n",
    "\n",
    "url = 'https://www.pearvideo.com/popular'\n",
    "page_text = session.get(url=url).content.decode('utf-8')\n",
    "# print(session.headers)\n",
    "# print(requests.utils.dict_from_cookiejar(session.cookies))\n",
    "\n",
    "tree = etree.HTML(page_text)\n",
    "li_list = tree.xpath('//ul[@id=\"popularList\"]/li')\n",
    "urls = []\n",
    "for li in li_list:\n",
    "    v_id = li.xpath('./div/a/@href')[0].split('_')[-1]\n",
    "    name = li.xpath('./div/a/h2/text()')[0]+'.mp4'\n",
    "    # 利用正则表达式替换文件名中的非法字符\n",
    "    name = re.sub(r'[\\\\/:*?\"<>|\\s]', '_', name)\n",
    "    video_url = f\"https://www.pearvideo.com/videoStatus.jsp\"\n",
    "    params = {\n",
    "        'contId': v_id,\n",
    "        'mrd': random.random()\n",
    "    }\n",
    "    # Referer是请求头的一部分 用来标识请求是从哪个页面发起的\n",
    "    headers = {'Referer': f'https://www.pearvideo.com/video_{v_id}'}\n",
    "    video_ajax = session.get(url=video_url, headers=headers, params=params).content.decode('utf-8')\n",
    "    video_json = json.loads(video_ajax)\n",
    "    # 对比真实视频地址和原始视频地址的区别\n",
    "    origin_url = video_json['videoInfo']['videos']['srcUrl']\n",
    "    true_url = re.sub(r'/\\d*?-', '/cont-'+v_id+'-', origin_url)\n",
    "    dic = {\n",
    "        'name': name,\n",
    "        'url': true_url\n",
    "    }\n",
    "    urls.append(dic)\n",
    "# print(urls)\n",
    "\n",
    "def get_video_data(dic):\n",
    "    url = dic['url']\n",
    "    data = session.get(url=url).content\n",
    "    # 持久化存储操作\n",
    "    with open('./videos/'+dic['name'], 'wb') as fp:\n",
    "        fp.write(data)\n",
    "        print(f\"{threading.get_native_id()} {dic['name']} 下载成功!\")\n",
    "\n",
    "# 单线程\n",
    "# for dic in urls:\n",
    "#     get_video_data(dic)\n",
    "# 使用线程池对视频数据进行请求 较为耗时的阻塞操作\n",
    "pool = Pool(4)\n",
    "pool.map(get_video_data, urls)\n",
    "pool.close()\n",
    "pool.join()\n",
    "end_time = time.time()\n",
    "print(f\"下载视频耗时: {end_time-start_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以史为镜，情缘相连。文物修复师恋人探寻前世，以期今生.mp4 下载成功!\n",
      "#两极穿越龙江行｜东极黑瞎子岛的岛主竟然是萌呆的黑熊们.mp4 下载成功!\n",
      "微短剧《赵小姐的日记》｜一本日记，两段情缘。.mp4 下载成功!\n",
      "以为夏天的哈尔滨不会有雪，梦幻冰雪馆让你过足冰雪瘾！.mp4 下载成功!\n",
      "网剧_1818_编辑部___网络世界迷人眼.mp4 下载成功!\n",
      "奶奶的新时代.mp4 下载成功!\n",
      "网台同播纪录片《赶集故事会》走进百姓生活_感受众生百态.mp4 下载成功!\n",
      "#两极穿越龙江行｜世界慢慢游,去18度的漠河避暑两日游攻略.mp4 下载成功!\n",
      "少年般绚丽.mp4 下载成功!\n",
      "如今可选择的选项越来越多，有选择困难症怎么破？.mp4 下载成功!\n",
      "下载视频耗时: 2.623565196990967 s\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from lxml import etree\n",
    "import re, json, os, time\n",
    "\n",
    "# 使用 aiohttp 的 ClientSession 进行异步 HTTP 请求\n",
    "# text()返回字符串形式的响应数据\n",
    "# read()返回的二进制形式的响应数据\n",
    "# json()返回的就是json对象\n",
    "# 注意：获取响应数据操作之前一定要使用await进行手动挂起\n",
    "\n",
    "async def fetch_page(url, session):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.text(encoding='utf-8')\n",
    "\n",
    "async def fetch_json(url, session, params, headers):\n",
    "    async with session.get(url, params=params, headers=headers) as response:\n",
    "        return await response.json(encoding='utf-8')\n",
    "\n",
    "async def download_video(dic, session):\n",
    "    url = dic['url']\n",
    "    async with session.get(url) as response:\n",
    "        data = await response.read()\n",
    "        # 持久化存储操作\n",
    "        with open('./videos/' + dic['name'], 'wb') as fp:\n",
    "            fp.write(data)\n",
    "            print(f\"{dic['name']} 下载成功!\")\n",
    "\n",
    "async def main():\n",
    "    # 不使用with的话需要手动关闭session\n",
    "    async with aiohttp.ClientSession(headers={\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36',\n",
    "        'NAME': 'Decade'\n",
    "    }) as session:\n",
    "        # 获取主页内容\n",
    "        page_text = await fetch_page('https://www.pearvideo.com/popular', session)\n",
    "        tree = etree.HTML(page_text)\n",
    "        li_list = tree.xpath('//ul[@id=\"popularList\"]/li')\n",
    "        urls = []\n",
    "\n",
    "        # 获取每个视频的详细信息\n",
    "        for li in li_list:\n",
    "            v_id = li.xpath('./div/a/@href')[0].split('_')[-1]\n",
    "            name = li.xpath('./div/a/h2/text()')[0] + '.mp4'\n",
    "            # 利用正则表达式替换文件名中的非法字符\n",
    "            name = re.sub(r'[\\\\/:*?\"<>|\\s]', '_', name)\n",
    "            video_url = f\"https://www.pearvideo.com/videoStatus.jsp\"\n",
    "            params = {\n",
    "                'contId': v_id,\n",
    "                'mrd': random.random()\n",
    "            }\n",
    "            headers = {'Referer': f'https://www.pearvideo.com/video_{v_id}'}\n",
    "            video_json = await fetch_json(video_url, session, params, headers)\n",
    "            origin_url = video_json['videoInfo']['videos']['srcUrl']\n",
    "            true_url = re.sub(r'/\\d*?-', '/cont-' + v_id + '-', origin_url)\n",
    "            dic = {\n",
    "                'name': name,\n",
    "                'url': true_url\n",
    "            }\n",
    "            urls.append(dic)\n",
    "\n",
    "        # 创建任务并下载视频\n",
    "        tasks = [\n",
    "            asyncio.create_task(download_video(dic, session)) for dic in urls\n",
    "        ]\n",
    "        await asyncio.wait(tasks)\n",
    "\n",
    "if not os.path.exists('./videos'):\n",
    "    os.mkdir('./videos')\n",
    "    \n",
    "start_time = time.time()\n",
    "await main()\n",
    "end_time = time.time()\n",
    "print(f\"下载视频耗时: {end_time-start_time} s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
